---
title: "Tim-Tuite-Bayes-Project-RB"
output: html_document
---


```{r load packages, message = FALSE, include = FALSE}

#install packages if needed
if(!require(tidyverse)) install.packages('tidyverse') 
library(tidyverse)
if(!require(data.table)) install.packages('data.table')
library(data.table)
if(!require(XML)) install.packages('XML')
library(XML)
if(!require(DAAG)) install.packages('DAAG') 
library(DAAG)
if(!require(glmnet)) install.packages('glmnet') 
library(glmnet)
if(!require(outliers)) install.packages('outliers')
library(outliers)
if(!require(plyr)) install.packages('plyr')
library(plyr)
if(!require(RCurl)) install.packages('RCurl')
library(RCurl)
if(!require(rvest)) install.packages('rvest')
library(rvest)
if(!require(GGally)) install.packages('GGally')
library(GGally)
if(!require(magrittr)) install.packages('magrittr')
library(magrittr)
if(!require(broom)) install.packages('broom')
library(broom)
if(!require(rjags)) install.packages('rjags')
library(rjags)
if(!require(vctrs)) install.packages('vctrs') 
library(vctrs)
if(!require(devtools)) install.packages('devtools')
library(devtools)
#install_github("willdebras/profootballref")

```



*******************************************************************************************************************************

## Analysis   
  
The first thing we need to do is to import the data. 
```{r load real next gen stats data}

#scrape 2019 next gen data from github, separated by position: https://github.com/mrcaseb/nfl-data/tree/master/data/ngs
#Examples of NFL data sources:
#https://rpubs.com/Nate_Bean/660747
#I was originally able to scrape it from the website, but it was unstable, so adding in the file itself
#setwd("C:/Users/timtu/Documents/GTX/R-Scripts/Bayesian-Statistics/Final Project")
next_gen_2019_rb <- read_csv("ngs_2019_rushing.csv")
next_gen_2019_rb$Player_Name <- paste(next_gen_2019_rb$player_first_name, next_gen_2019_rb$player_last_name)
next_gen_2019_rb$Player_Name <- gsub(' ', '', next_gen_2019_rb$Player_Name)

#detach(package:plyr) #plyr causes issues with the groupby https://stackoverflow.com/questions/26923862/why-are-my-dplyr-group-by-summarize-not-working-properly-name-collision-with
#actually week 0 is the regular season totals, so we can just filter on week 0 to get the totals, but restrict it to our variables

#or probably better to do averages, since otherwise it's just a compilation of stats that overvalues totals...may have to reincorporate qb grouping/mean format
# next_gen_2019_rb_grouped <- next_gen_2019_rb %>% 
#   filter(season_type == "REG") %>%
#   filter(week == 0) %>% #week 0 is the season totals
#   select(Player_Name, efficiency, percent_attempts_gte_eight_defenders, avg_time_to_los, rush_attempts, rush_yards, expected_rush_yards, rush_yards_over_expected, avg_rush_yards, rush_yards_over_expected_per_att, rush_pct_over_expected, rush_touchdowns) 

#per-game stats
next_gen_2019_rb_grouped <- next_gen_2019_rb %>% 
  filter(season_type == "REG") %>%
  filter(between(week, 1, 17)) %>%
  group_by(Player_Name) %>%
  filter(n() >= 8) %>%  #only include players who played in at least 8 games
  summarize_at(vars(efficiency, percent_attempts_gte_eight_defenders, avg_time_to_los, rush_attempts, rush_yards, expected_rush_yards, rush_yards_over_expected, avg_rush_yards, rush_yards_over_expected_per_att, rush_pct_over_expected, rush_touchdowns), mean) 


```


```{r load fantasy data}

#get the fantasy stats for 2019
fantasy_stats2019 <- profootballref::gen_tables(year = 2019) 
#cleanup the fantasy point data 
fantasy_stats2019 <- as.data.frame(cbind(fantasy_stats2019$Player, fantasy_stats2019$FantPos, fantasy_stats2019$Fantasy_FantPt, fantasy_stats2019$Fantasy_VBD, fantasy_stats2019$Fantasy_PosRank, fantasy_stats2019$Fantasy_OvRank))

#replace the special characters and spaces with blank
fantasy_stats2019$V1 <- gsub('\\*', '', fantasy_stats2019$V1)
fantasy_stats2019$V1 <- gsub('\\+', '', fantasy_stats2019$V1)
fantasy_stats2019$V1 <- gsub(' ', '', fantasy_stats2019$V1)

fantasy_stats2019[c("V3","V4", "V5", "V6")] <- sapply(fantasy_stats2019[c("V3","V4", "V5", "V6")], as.numeric)

fantasy_stats2019 <- fantasy_stats2019 %>%
  dplyr::rename(
    Player_Name = "V1",
    Fantasy_Position = "V2",
    Total_Fantasy_Points = "V3",
    Value_Over_Baseline = "V4",
    Position_Rank = "V5",
    Overall_Rank = "V6"
    )

```

  
  
```{r merge next-gen and fantasy data}

#join the fantasy and next gen data on player name
rb_merged_nxtgen_fantasy <- merge(next_gen_2019_rb_grouped, fantasy_stats2019, by = "Player_Name") 

#replace NA's in the VBD with 0 
rb_merged_nxtgen_fantasy$Value_Over_Baseline[is.na(rb_merged_nxtgen_fantasy$Value_Over_Baseline)] <- 0

head(rb_merged_nxtgen_fantasy)

```

```{r exploratory data analysis - summary}

#summarize the dataset
summary(rb_merged_nxtgen_fantasy)


#this gives the view of the first few rows of the highest-scoring players.
rb_merged_nxtgen_fantasy %>% arrange(desc(Total_Fantasy_Points)) %>% head()


```

We'll also explore different correlations between different variables. 

```{r correlation}

#create a matrix with just numeric values, and ignore other dependent variables that are not fantasy points as that's not what we're predicting
rb_merged_nxtgen_fantasy_matrix <- as.matrix(rb_merged_nxtgen_fantasy %>% select(efficiency, percent_attempts_gte_eight_defenders, avg_time_to_los, rush_attempts, rush_yards, expected_rush_yards, rush_yards_over_expected, avg_rush_yards, rush_yards_over_expected_per_att, rush_pct_over_expected, rush_touchdowns, Total_Fantasy_Points))

#create a correlation matrix based on the above matrix 
ggcorr(rb_merged_nxtgen_fantasy_matrix, nbreaks = 5, geom = 'text', label_alpha = TRUE, angle = -15)

#there is some multicollinearity, which makes sense since a lot of these variables are similar. However, for Bayesian regression, we still expect the MCMC to converge to the true values for the different parameters, so we can leave the data as is.  
#That being said, we'll exclude rushing yards and rushing touchdowns in the model, since these are directly related to the total fantasy points (i.e. they're part of the calculation), so we already know these are related. We're more interested in underlying factors. 

#we look at the right column to see the following variables look to be the most correlated with Total Fantasy Points (cutoff of .3):
##expected_rush_yards
##rush_yards_over_expected
##avg_rush_yards
##rush_yards_over_expected_per_att
##rush_attempts
##rush_pct_over_expected

#We'll plot this association between expected rush yards and total fantasy points just to get an idea of how one of the strongest correlations looks like, though not that strong of a linear relationship. 
rb_merged_nxtgen_fantasy %>%
  ggplot(aes(expected_rush_yards, Total_Fantasy_Points)) +
  geom_point(alpha = .5)

#We'll use linear regression to get a better understanding of what's needed soon. 


```



**************************************************************************************************************************
  
The first model we'd like to build is a Bayesian linear regression model to see the effects of the variables on overall points scored, using only variables with strong enough correlation to Total Fantasy Points.

We'll keep these variables expected_rush_yards, rush_pct_over_expected, rush_attempts, rush_yards_over_expected, avg_rush_yards, rush_yards_over_expected_per_att.

```{r Bayes linear regression rb1}

mod_rb_string_1 = " model {

    #likelihood
    for (k in 1:n) {
        Tot_Fant_Pts[k] ~ dnorm(mu[k], tau)
        mu[k] <- b[1] + 
        b[2]*exp_rush_yds[k] + 
        b[3]*rush_pct_over_exp[k] + 
        b[4]*rush_att[k] + 
        b[5]*rush_yds_over_exp[k] + 
        b[6]*avg_rush_yds[k] +
        b[7]*rush_yds_over_exp_per_att[k]
    }
    
    #set non-informative priors on the betas
    for (p in 1:7) {
        b[p] ~ dnorm(0.0, 0.001)
    }

    #priors on the other non-beta parameters
    tau ~ dgamma(0.01, 0.01) 
    
} "

```

After writing our model, we sample from it using our data, and summarize the results: 
```{r use model rb1}

#here we setup the data that will be used in the above model
set.seed(72)
data_rb_jags = list(Tot_Fant_Pts = rb_merged_nxtgen_fantasy$Total_Fantasy_Points,  
                    exp_rush_yds = rb_merged_nxtgen_fantasy$expected_rush_yards,
                    rush_pct_over_exp = rb_merged_nxtgen_fantasy$rush_pct_over_expected,
                    rush_att = rb_merged_nxtgen_fantasy$rush_attempts,
                    rush_yds_over_exp = rb_merged_nxtgen_fantasy$rush_yards_over_expected,
                    avg_rush_yds = rb_merged_nxtgen_fantasy$avg_rush_yards,
                    rush_yds_over_exp_per_att = rb_merged_nxtgen_fantasy$rush_yards_over_expected_per_att,
                    n = nrow(rb_merged_nxtgen_fantasy)
                    )

params_rb_1 = c("b")  #these are the parameters that we're trying to estimate from the model above


#we create the model using that model string above and the data above
mod_rb_1 = jags.model(textConnection(mod_rb_string_1), data=data_rb_jags, n.chains=3)
update(mod_rb_1, 1000) # burn-in

#we simulate the model and the parameters 10000 times
mod_rb_1_sim = coda.samples(model=mod_rb_1,
                       variable.names=params_rb_1,
                       n.iter=50000)
mod_rb_1_csim = do.call(rbind, mod_rb_1_sim)

#we plot the traceplots of the different parameters
plot(mod_rb_1_sim)

#we output the summary of the model
summary(mod_rb_1_sim)

```




**********************************************************************************************************************

To do some further analysis (lasso regression), we'd like to scale the data so that the effect of certain variables do not overwhelm values on other variables. 

```{r scale data}

#we're going to be selecting certain variables and analyzing the effects of those variables on projected points. We have to scale the data to prevent outsized effects of certain variables. This needs to be done on the continuous (i.e. not categorical) variables...we'll exclude rush yards and rush touchdowns like in the first model
scaled_rb <- rb_merged_nxtgen_fantasy %>% mutate_each_(funs(scale(.) %>% as.vector),
                       vars = c('efficiency', 'percent_attempts_gte_eight_defenders', 'avg_time_to_los', 'rush_attempts', 'expected_rush_yards', 'rush_yards_over_expected', 'avg_rush_yards', 'rush_yards_over_expected_per_att', 'rush_pct_over_expected', 'Total_Fantasy_Points')) %>% select(-c(rush_yards, rush_touchdowns))


head(scaled_rb)
```




Now that we've scaled the data, we can use LASSO regression to select certain values based on a budget on the sum of the coefficients. LASSO is a global optimization variable selection method, that keeps the most important coefficients and drops the less important coefficients to 0 (thus removing the variable from the model). There is a more generalized version of LASSO (Elastic Net), which we'll explore here too.
```{r variable selection}


#prepare data to be used in glmnet, by creating a predictors matrix holding the numeric variables and a response matrix for the fantasy points
rb_predictors <- as.matrix(scaled_rb[, 2:10])
rb_response_fantpts <- as.matrix(scaled_rb[, 12]) %>% `colnames<-`('Total_Fantasy_Points')


set.seed(1)

#we can use elastic net to tune alpha. The closer alpha is to 1, the more it behaves like lasso regression, which tends to be better for picking variables. The closer alpha is to 1, the more it behaves like ridge regression, which tends to be better for minimizing prediction error. We'll use R^2 as the measuure of quality for each iteration.

#####################

#run for alpha = 0
elastic_net_glm_0 <- cv.glmnet(x = rb_predictors, y = rb_response_fantpts, family = "gaussian", nfolds = 10, alpha = 0)
small_lambda_index_0 <- which(elastic_net_glm_0$lambda == elastic_net_glm_0$lambda.min)
small_lambda_betas_0 <- elastic_net_glm_0$glmnet.fit$beta[, small_lambda_index_0]


#calculate the r-squared
r2 <- elastic_net_glm_0$glmnet.fit$dev.ratio[which(elastic_net_glm_0$glmnet.fit$lambda == elastic_net_glm_0$lambda.min)]

#add results to a dataframe
elastic_net_results <- tibble(Alpha = '0', Rsquared = r2)


#####################

#run for alpha .25
elastic_net_glm_0.25 <- cv.glmnet(x = rb_predictors, y = rb_response_fantpts, family = "gaussian", nfolds = 10, alpha = 0.25)
small_lambda_index_0.25 <- which(elastic_net_glm_0.25$lambda == elastic_net_glm_0.25$lambda.min)
small_lambda_betas_0.25 <- elastic_net_glm_0.25$glmnet.fit$beta[, small_lambda_index_0.25]

#calculate the r-squared
r2_0.25 <- elastic_net_glm_0.25$glmnet.fit$dev.ratio[which(elastic_net_glm_0.25$glmnet.fit$lambda == elastic_net_glm_0.25$lambda.min)]

#create an entry in the R^2 table for this method
elastic_net_results <- bind_rows(elastic_net_results,
                          tibble(Alpha = '0.25', Rsquared = r2_0.25))


#####################

#run for alpha .5
elastic_net_glm_0.5 <- cv.glmnet(x = rb_predictors, y = rb_response_fantpts, family = "gaussian", nfolds = 10, alpha = 0.5)
small_lambda_index_0.5 <- which(elastic_net_glm_0.5$lambda == elastic_net_glm_0.5$lambda.min)
small_lambda_betas_0.5 <- elastic_net_glm_0.5$glmnet.fit$beta[, small_lambda_index_0.5]


#calculate the r-squared
r2_0.5 <- elastic_net_glm_0.5$glmnet.fit$dev.ratio[which(elastic_net_glm_0.5$glmnet.fit$lambda == elastic_net_glm_0.5$lambda.min)]


#add results to table
elastic_net_results <- bind_rows(elastic_net_results,
                          tibble(Alpha = '0.5', Rsquared = r2_0.5))


#####################

#run for alpha .75
elastic_net_glm_0.75 <- cv.glmnet(x = rb_predictors, y = rb_response_fantpts, family = "gaussian", nfolds = 10, alpha = 0.75)
small_lambda_index_0.75 <- which(elastic_net_glm_0.75$lambda == elastic_net_glm_0.75$lambda.min)
small_lambda_betas_0.75 <- elastic_net_glm_0.75$glmnet.fit$beta[, small_lambda_index_0.75]


#calculate the r-squared
r2_0.75 <- elastic_net_glm_0.75$glmnet.fit$dev.ratio[which(elastic_net_glm_0.75$glmnet.fit$lambda == elastic_net_glm_0.75$lambda.min)]


#add results to table
elastic_net_results <- bind_rows(elastic_net_results,
                          tibble(Alpha = '0.75', Rsquared = r2_0.75))



####################

#run for alpha 1
elastic_net_glm_1 <- cv.glmnet(x = rb_predictors, y = rb_response_fantpts, family = "gaussian", nfolds = 10, alpha = 1)
small_lambda_index_1 <- which(elastic_net_glm_1$lambda == elastic_net_glm_1$lambda.min)
small_lambda_betas_1 <- elastic_net_glm_1$glmnet.fit$beta[, small_lambda_index_1]


#calculate the r-squared
r2_1 <- elastic_net_glm_1$glmnet.fit$dev.ratio[which(elastic_net_glm_1$glmnet.fit$lambda == elastic_net_glm_1$lambda.min)]


#add results to table
elastic_net_results <- bind_rows(elastic_net_results,
                          tibble(Alpha = '1', Rsquared = r2_1))

elastic_net_results %>% knitr::kable()


#############
#From this, we see the best R-squared is when alpha = .5. We'll output this model's coefficients:
dput(sort(small_lambda_betas_0.5))

```

From this, we see the best R^2 value is when alpha = 0.5. This is a global variable selection approach which selects which variables are most useful, subject to a constraint of how much can be allocated to each variable. Values with 0 or very close to 0 can definitely be removed from the model, using |0.05| as a cutoff. That leaves these variables:  
- avg_time_to_los  
- efficiency  
- rush_attempts  
- expected_rush_yards  
- avg_rush_yards

  
```{r Bayes linear regression}

mod_rb_string_2 = " model {

    #likelihood
    for (k in 1:n) {
        Tot_Fant_Pts[k] ~ dnorm(mu[k], tau)
        mu[k] <- b[1] + 
        b[2]*avg_time_los[k] +
        b[3]*efficiency[k] +
        b[4]*rush_att[k] +
        b[5]*exp_rush_yds[k] +
        b[6]*avg_rush_yds[k]
        
    }
    
    #set non-informative priors on the betas
    for (p in 1:6) {
        b[p] ~ dnorm(0.0, 0.001)
    }

    #priors on the other non-beta parameters
    tau ~ dgamma(0.01, 0.01) 
    
} "

```

After writing our model, we sample from it using our data, and summarize the results: 
```{r use model}

#here we setup the data that will be used in the above model
set.seed(72)
data_rb_jags_2 = list(Tot_Fant_Pts = rb_merged_nxtgen_fantasy$Total_Fantasy_Points,  
                    avg_time_los = rb_merged_nxtgen_fantasy$avg_time_to_los,
                    efficiency = rb_merged_nxtgen_fantasy$efficiency,
                    rush_att = rb_merged_nxtgen_fantasy$rush_attempts, 
                    avg_rush_yds = rb_merged_nxtgen_fantasy$avg_rush_yards,
                    exp_rush_yds = rb_merged_nxtgen_fantasy$expected_rush_yards,
                    n = nrow(rb_merged_nxtgen_fantasy)
                    )

params_rb_2 = c("b")  #these are the parameters that we're trying to estimate from the model above


#we create the model using that model string above and the data above
mod_rb_2 = jags.model(textConnection(mod_rb_string_2), data=data_rb_jags_2, n.chains=3)
update(mod_rb_2, 1000) # burn-in

#we simulate the model and the parameters 5000 times
mod_rb_2_sim = coda.samples(model=mod_rb_2,
                       variable.names=params_rb_2,
                       n.iter=50000)
mod_rb_2_csim = do.call(rbind, mod_rb_2_sim)

#we plot the traceplots of the different parameters
plot(mod_rb_2_sim)

#we output the summary of the model
summary(mod_rb_2_sim)

```
  
**********************************************************************************************************

I also attempted Bayesian variable selection through Stochastic Search Variable Selection to identify which parameters are most likely to be important for the model by seeing which model is most visited by the Gibbs sampler:
```{r bayesian variable selection}
#https://darrenjw.wordpress.com/2012/11/20/getting-started-with-bayesian-variable-selection-using-jags-and-rjags/

#setup our data as the scaled qb data
data_jags_rb_varselect =list(y=scaled_rb[,12],
                     X=scaled_rb[,2:10],
                     n=nrow(scaled_rb),
                     p=ncol(scaled_rb[,2:10]))

in_model_matrix_rb <- matrix(data = NA, nrow = data_jags_rb_varselect$n, data_jags_rb_varselect$p)

model_3_rb_varselect_string ="
  model {
    for (i in 1:n) {
      y[i]~dnorm(mean[i],tau)
      mean[i]<-int+inprod(X[i,],beta)
    }
    for (j in 1:p) {
      delta[j]~dbern(0.25) #prior probability xi is in the model
      alpha[j]~dnorm(0,0.1)
      beta[j]<-delta[j]*alpha[j]
    }
    int~dnorm(0,0.0001)
    tau~dgamma(1,0.001)
    #pind~dbeta(1,2)  #hyperprior on the prior probability of variable in model. beta with mean .33
    
    
    #get the model sequence, where 2 means variable in the model...start small to see if it works...
    for (j1 in 1:2){for(j2 in 1:2){for(j3 in 1:2){for(j4 in 1:2){for(j5 in 1:2){for(j6 in 1:2){for(j7 in 1:2){for(j8 in 1:2){for(j9 in 1:2){
        
        in_model_matrix_rb[j1, j2, j3, j4, j5, j6, j7, j8, j9] <- ifelse(delta[1] == j1-1, 1, 0)*ifelse(delta[2] == j2-1, 1, 0)*ifelse(delta[3] == j3-1, 1, 0)*ifelse(delta[4] == j4-1, 1, 0)*ifelse(delta[5] == j5-1, 1, 0)*ifelse(delta[6] == j6-1, 1, 0)* ifelse(delta[7] == j7-1, 1, 0)* ifelse(delta[8] == j8-1, 1, 0)* ifelse(delta[9] == j9-1, 1, 0)
        
    }}}}}}}}}
   }
"
model_3_rb_varselect =jags.model(textConnection(model_3_rb_varselect_string),
                data=data_jags_rb_varselect,
                n.chains = 2)
update(model_3_rb_varselect,n.iter=50)
output_rb = coda.samples(model=model_3_rb_varselect,
        variable.names=c("delta", "in_model_matrix_rb"),
        n.iter=10000,thin=1)
summary_rb_var_selection <- summary(output_rb)
#plot(output)

#the means of the deltas say how often the variable was 1 (included int he model)
```

Checking the results, searching for the row with the largest mean value of in_model_matrix_rb, which has a probability of 0.329).  

The model visits this model 21.1% of the time.  

This uses parameters 5 and 7 in the model (where the index is 2).
```{r}

head(sort(summary_rb_var_selection$statistics[,c('Mean')], TRUE), 10)
# delta[7]                              delta[5] 
#                                 0.686                                 0.580 
# in_model_matrix_rb[1,1,1,1,2,1,2,1,1] in_model_matrix_rb[1,1,1,1,1,1,2,1,1] 
#                                 0.329                                 0.148 
#                              delta[8]                              delta[4] 
#                                 0.145                                 0.139 
#                              delta[6] in_model_matrix_rb[1,1,1,1,2,1,1,1,1] 
#                                 0.114                                 0.088 
# in_model_matrix_rb[1,1,1,2,1,1,2,1,1] in_model_matrix_rb[1,1,1,1,1,1,1,2,1] 
#                                 0.088                                 0.060

# head(sort(summary_qb_var_selection$statistics, TRUE))
# #[1] 0.5380000 0.4988034 0.4525879 0.3827041 0.3801572 0.3239505
# sort(summary_qb_var_selection$statistics, TRUE)[2]
# #[1] 0.4988034
# which(summary_qb_var_selection$statistics == sort(summary_qb_var_selection$statistics,TRUE)[2])[1]
# #[1] 131101
```


We'll run the bayes regression model based on those 2 parameters + the intercept
```{r Bayes linear reg after ssvs}

mod_rb_string_3 = " model {

    #likelihood
    for (k in 1:n) {
        Tot_Fant_Pts[k] ~ dnorm(mu[k], tau)
        mu[k] <- b[1] + 
        b[2]*exp_rush_yds[k] +
        b[3]*avg_rush_yds[k]
    }
    
    #set non-informative priors on the betas
    for (p in 1:3) {
        b[p] ~ dnorm(0.0, 0.001)
    }

    #priors on the other non-beta parameters
    tau ~ dgamma(0.01, 0.01) 
    
} "

set.seed(72)
data_rb_jags_3 = list(Tot_Fant_Pts = rb_merged_nxtgen_fantasy$Total_Fantasy_Points,  
                    exp_rush_yds = rb_merged_nxtgen_fantasy$expected_rush_yards,
                    avg_rush_yds = rb_merged_nxtgen_fantasy$avg_rush_yards,
                    n = nrow(rb_merged_nxtgen_fantasy)
                    )

params_rb_3 = c("b")  #these are the parameters that we're trying to estimate from the model above


#we create the model using that model string above and the data above
mod_rb_3 = jags.model(textConnection(mod_rb_string_3), data=data_rb_jags_3, n.chains=3)
update(mod_rb_3, 1000) # burn-in

#we simulate the model and the parameters 5000 times
mod_rb_3_sim = coda.samples(model=mod_rb_3,
                       variable.names=params_rb_3,
                       n.iter=50000)
mod_rb_3_csim = do.call(rbind, mod_rb_3_sim)

#we plot the traceplots of the different parameters
plot(mod_rb_3_sim)

#we output the summary of the model
summary(mod_rb_3_sim)


```

**********************************************************************************************************

```{r measure model DIC}
dic_rb_mod1 <- dic.samples(mod_rb_1, n.iter = 1000)
dic_rb_mod2 <- dic.samples(mod_rb_2, n.iter = 1000)
dic_rb_mod3 <- dic.samples(mod_rb_3, n.iter = 1000)
print(dic_rb_mod1)
print(dic_rb_mod2)
print(dic_rb_mod3)
#dic_qb_mod3 <- dic.samples(mod_qb_3, n.iter = 100)
#diffdic(dic_rb_mod1, dic_rb_mod2)  #mod1 is preferred because the penalized deviance of mod1 < penalized deviance of mod2

```

